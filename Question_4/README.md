# Question 4
>
> *Streaming Data:* testing Kafka, Spark, Hadoop, HDFS.
>
>   4.1. *Kafka* Quickstart , <https://kafka.apache.org/quickstart>:
>
>       4.1.1. High level explanation of Kafkaâ€™s structure:
>			4.1.1.1. *Concepts:* Explain the following Kafka concepts: "Kafka is run as a cluster on one or more servers" ; "The Kafka cluster stores streams of records in categories called topics" ; "Each record consists of a key, a value, and a timestamp".
>			4.1.1.2. Kafka has four core *APIs*, explain each one of them: "Producer API" ; "Consumer API" ; "Streams API" ; "Connector API".
>		4.1.2. Deploy a bare bones Kafka/Zookeeper server:
>           4.1.2.1. Create a topic; Send some sample messages; Dump the messages on standard output (consumer); Use Connect to import/export data.
>           4.1.2.2. *Bonus:* run the WordCountDemo, <https://kafka.apache.org/10/documentation/streams/quickstart>.
>
>   4.2. *Spark, Hadoop, HDFS:* quickstart:
>
>		4.2.1. Deploy Spark in standalone mode, and run a couple of examples through your newly deployed Spark server: <https://mbonaci.github.io/mbo-spark/> ;<https://spark.apache.org/docs/latest/spark-standalone.html>.

## Solution
